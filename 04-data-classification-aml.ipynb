{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show how to perform text classification by fine-tuning a BERT-based model, running the fine-tuning procedure as a distributed training job on Azure ML.\n",
    "\n",
    "For more details about distributed training on Azure ML, please see [here]( https://github.com/microsoft/DistributedDeepLearning/).\n",
    "\n",
    "Please notice that this notebook was create in a hosted Jupyter environment on Azure ML. This environment already has all packages we need here such as NumPy, Pandas, Scikit-Learn, and PyTorch. For details about this hosted environment, please see [here]( https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-1st-experiment-sdk-setup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run, Environment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "from azureml.train.dnn import PyTorch\n",
    "from azureml.train.hyperdrive import GridParameterSampling\n",
    "from azureml.train.hyperdrive import HyperDriveConfig\n",
    "from azureml.train.hyperdrive import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice\n",
    "\n",
    "from azureml.core.runconfig import MpiConfiguration\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to interact with Azure ML, we first need to get a reference to our [workspace]( https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace).\n",
    "\n",
    "We use the [Azure ML SDK]( https://docs.microsoft.com/en-us/python/api/overview/azureml-sdk/?view=azure-ml-py) for that. If you don’t have it installed into your development environment, please follow the instructions [here]( https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-environment#local). If you want to run the code on a managed VM instance, which already has the SDK, please see [here]( https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-1st-experiment-sdk-setup).\n",
    "\n",
    "You need to replace the values for *subscription_id*, *resource_group*, and *workspace_name* with the values for your own corresponding resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "\n",
    "subscription_id = '<your azure subscription id>'\n",
    "resource_group = '<your azure ml workspace resource group>'\n",
    "workspace_name = '<your azure ml workspace name>'\n",
    "\n",
    "workspace = Workspace(subscription_id=subscription_id, resource_group=resource_group, workspace_name=workspace_name,\n",
    "                      auth=interactive_auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we instantiate an [Experiment]( https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiments) object, which will later be used to submit our model training execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(workspace = workspace, name = 'bert_text_classification_distributed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create our remote [Compute Target]( https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-targets).\n",
    "\n",
    "Here we create one of the type [Azure Machine Learning Compute]( https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute). Once created, this resource is persisted and accessible by its name in subsequent calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new compute target...\n",
      "Creating\n",
      "Succeeded....................\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "cluster_name = 'aml-compute-01'\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace = workspace, name = cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size = 'STANDARD_NC6', min_nodes = 8, max_nodes = 8)\n",
    "    compute_target = ComputeTarget.create(workspace, cluster_name, compute_config)\n",
    "    compute_target.wait_for_completion(show_output = True, min_node_count = 8, timeout_in_minutes = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create an [Estimator]( https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-azure-machine-learning-architecture#estimators) object, which facilitate the creation of run configurations, by defining run scripts, its parameters and the target run environment.\n",
    "\n",
    "AML service provides a generic Estimator, as well as specialized ones that facilitate the usage of several popular python ML packages. Here we use the [PyTorch Estimator]( https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.estimator?view=azure-ml-py), as we are going to train a PyTorch based model.\n",
    "\n",
    "The code that runs on the remote compute target is specified in the *entry_script* field. It is basically the same code that we use in the notebook *02-data-classification*, where we explain how to perform the fine-tuning step-by-step, but here without the visualizations and including the necessary arguments parsing, specific Azure ML logging and saving the model artifacts of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - framework_version is not specified, defaulting to version 1.3.\n"
     ]
    }
   ],
   "source": [
    "script_folder = './training_script'\n",
    "\n",
    "script_params = {\n",
    "    '--dataset_name': 'Consumer Complaints Dataset'\n",
    "}\n",
    "\n",
    "estimator = PyTorch(source_directory = script_folder,\n",
    "                    compute_target = compute_target,\n",
    "                    entry_script = 'train_horovod.py',\n",
    "                    script_params = script_params,\n",
    "                    use_gpu = True,\n",
    "                    node_count=8,\n",
    "                    process_count_per_node=1,\n",
    "                    distributed_training=MpiConfiguration(),\n",
    "                    pip_packages = ['sklearn', 'transformers', 'azureml-dataprep[fuse,pandas]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to submit our Estimator for remote run on AML Compute. Instead of doing that directly, we will wrap it using the [HyperDrive]( https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters) functionality for automated model hyperparameter search.\n",
    "\n",
    "The first step is to define how to sample the hyperparameter space. AML service provides several strategies already built in. Here we will use standard [Grid Sampling]( https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters#sampling-the-hyperparameter-space).\n",
    "\n",
    "The hyperparameter space is defined by the [choice]( https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.parameter_expressions?view=azure-ml-py) function. For simplicity and to exemplify only one combination of parameters, we have only one value for each *choice*. You could define as many values you want for each one in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_sampling = GridParameterSampling({\n",
    "    'batch_size': choice(32),\n",
    "    'learning_rate': choice(1e-5),\n",
    "    'adam_epsilon': choice(1e-8),\n",
    "    'num_epochs': choice(5)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the estimator and grid sampling strategy, we can pass them to the [Hyper Drive configuration]( https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py) object. There are several options to configure here, such as the [termination policy]( https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters#specify-early-termination-policy), [resources]( https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters#allocate-resources) to allocate the job on, and the [primary metric]( https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters#specify-primary-metric) to be optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run_config = HyperDriveConfig(estimator = estimator,\n",
    "                                         hyperparameter_sampling = param_sampling,\n",
    "                                         policy = None,\n",
    "                                         primary_metric_name = 'validation loss',\n",
    "                                         primary_metric_goal = PrimaryMetricGoal.MINIMIZE,\n",
    "                                         max_total_runs = 1,\n",
    "                                         max_concurrent_runs = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining step is to submit the Experiment defined before, passing the configuration fot the hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run = exp.submit(hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can monitor the execution through a Jupyter [graphical widget]( https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-tune-hyperparameters#visualize-experiment), available through the *RunDetails* class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e05d4d710a40b393f28eee18bdf1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/bert_text_classification_distributed/runs/bert_text_classification_distributed_1580183281896998?wsid=/subscriptions/a6c2a7cc-d67e-4a1a-b765-983f08c0423a/resourcegroups/alvilcek-ml-rg/workspaces/alvilcek-ml-workspace\", \"run_id\": \"bert_text_classification_distributed_1580183281896998\", \"run_properties\": {\"run_id\": \"bert_text_classification_distributed_1580183281896998\", \"created_utc\": \"2020-01-28T03:48:02.036579Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"validation loss\\\", \\\"goal\\\": \\\"minimize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"28799e81-0fbe-496b-ae7a-4fcce42318c7\"}, \"tags\": {\"max_concurrent_jobs\": \"1\", \"max_total_jobs\": \"1\", \"max_duration_minutes\": \"10080\", \"policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\"}\", \"generator_config\": \"{\\\"name\\\": \\\"GRID\\\", \\\"parameter_space\\\": {\\\"batch_size\\\": [\\\"choice\\\", [[32]]], \\\"learning_rate\\\": [\\\"choice\\\", [[1e-05]]], \\\"adam_epsilon\\\": [\\\"choice\\\", [[1e-08]]], \\\"num_epochs\\\": [\\\"choice\\\", [[5]]]}}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"validation loss\\\", \\\"goal\\\": \\\"minimize\\\"}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/a6c2a7cc-d67e-4a1a-b765-983f08c0423a/resourceGroups/alvilcek-ml-rg/providers/Microsoft.MachineLearningServices/workspaces/alvilcek-ml-workspace/experiments/bert_text_classification_distributed\\\", \\\"SubscriptionId\\\": \\\"a6c2a7cc-d67e-4a1a-b765-983f08c0423a\\\", \\\"ResourceGroupName\\\": \\\"alvilcek-ml-rg\\\", \\\"WorkspaceName\\\": \\\"alvilcek-ml-workspace\\\", \\\"ExperimentName\\\": \\\"bert_text_classification_distributed\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train_horovod.py\\\", \\\"arguments\\\": [\\\"--dataset_name\\\", \\\"Consumer Complaints Dataset\\\"], \\\"target\\\": \\\"aml-compute-01\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"IntelMpi\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 8, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\", \\\"NCCL_TREE_THRESHOLD\\\": \\\"0\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"sklearn\\\", \\\"transformers\\\", \\\"azureml-dataprep[fuse,pandas]\\\", \\\"azureml-defaults\\\", \\\"torch==1.3.1\\\", \\\"torchvision==0.4.1\\\", \\\"horovod==0.18.1\\\", \\\"tensorboard==1.14.0\\\", \\\"future==0.17.1\\\"]}], \\\"channels\\\": [\\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/base-gpu:openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 8}}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"28799e81-0fbe-496b-ae7a-4fcce42318c7\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"azureml.train.hyperdrive._search\\\", \\\"amlClientFunction\\\": \\\"search\\\", \\\"tenantId\\\": \\\"72f988bf-86f1-41af-91ab-2d7cd011db47\\\", \\\"amlClientRequestId\\\": \\\"038f99d2-7252-4256-85cf-513b3c598e36\\\", \\\"amlClientSessionId\\\": \\\"78087568-0f23-4b81-aa0d-0d615dabba76\\\", \\\"subscriptionId\\\": \\\"a6c2a7cc-d67e-4a1a-b765-983f08c0423a\\\", \\\"estimator\\\": \\\"PyTorch\\\", \\\"samplingMethod\\\": \\\"GRID\\\", \\\"terminationPolicy\\\": \\\"Default\\\", \\\"primaryMetricGoal\\\": \\\"minimize\\\", \\\"maxTotalRuns\\\": 1, \\\"maxConcurrentRuns\\\": 1, \\\"maxDurationMinutes\\\": 10080, \\\"computeTarget\\\": \\\"AmlCompute\\\", \\\"vmSize\\\": null}}}\", \"resume_child_runs\": \"null\", \"all_jobs_generated\": \"true\", \"cancellation_requested\": \"false\", \"progress_metadata_evaluation_timestamp\": \"\\\"2020-01-28T03:48:02.419097\\\"\", \"progress_metadata_digest\": \"\\\"413f467865cb1dc7cda12fb16b8a527663eed5ba0f9d8dc1bc371d5ebd7dd635\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2020-01-28T03:48:02.419097\\\"\", \"bert_text_classification_distributed_1580183281896998_0\": \"{\\\"batch_size\\\": 32, \\\"learning_rate\\\": 1e-05, \\\"adam_epsilon\\\": 1e-08, \\\"num_epochs\\\": 5}\", \"environment_preparation_status\": \"PREPARED\", \"prepare_run_id\": \"bert_text_classification_distributed_1580183281896998_preparation\"}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://alvilcekmlwork0917427776.blob.core.windows.net/azureml/ExperimentRun/dcid.bert_text_classification_distributed_1580183281896998/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=%2BSsI388ijaSQpDWsxz4eVSx7QE9RUTP%2F3odyKQwEyBU%3D&st=2020-01-28T03%3A43%3A13Z&se=2020-01-28T11%3A53%3A13Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:05:11\", \"hyper_parameters\": {\"batch_size\": [\"choice\", [[32]]], \"learning_rate\": [\"choice\", [[1e-05]]], \"adam_epsilon\": [\"choice\", [[1e-08]]], \"num_epochs\": [\"choice\", [[5]]]}}, \"child_runs\": [{\"run_id\": \"bert_text_classification_distributed_1580183281896998_0\", \"run_number\": 15, \"metric\": null, \"status\": \"Running\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-01-28T03:49:39.079779Z\", \"end_time\": \"\", \"created_time\": \"2020-01-28T03:48:33.652931Z\", \"created_time_dt\": \"2020-01-28T03:48:33.652931Z\", \"duration\": \"0:04:40\", \"hyperdrive_id\": \"1580183281896998\", \"arguments\": null, \"param_batch_size\": 32, \"param_learning_rate\": 1e-05, \"param_adam_epsilon\": 1e-08, \"param_num_epochs\": 5}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2020-01-28T03:48:02.179345][API][INFO]Experiment created\\r\\n[2020-01-28T03:48:02.504622][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2020-01-28T03:48:02.633035][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2020-01-28T03:48:02.8728295Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\r\\n[2020-01-28T03:48:32.538764][GENERATOR][INFO]Max number of jobs '1' reached for experiment.\\r\\n[2020-01-28T03:48:32.669860][GENERATOR][INFO]All jobs generated.\\r\\n[2020-01-28T03:48:33.2818862Z][SCHEDULER][INFO]Scheduling job, id='bert_text_classification_distributed_1580183281896998_0'\\r\\n[2020-01-28T03:48:33.2826387Z][SCHEDULER][INFO]The execution environment was successfully prepared.\\r\\n[2020-01-28T03:48:33.7260417Z][SCHEDULER][INFO]Successfully scheduled a job. Id='bert_text_classification_distributed_1580183281896998_0'\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.83\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all executions generated by the hyperparameter search finish, we can inspect them and print the hyperparameters and correspondig model performance metrics in a table.\n",
    "\n",
    "Here this table is ordered by the best model according to the Mean Absolute Error computed for the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adam_epsilon</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>validation loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1E-08</td>\n",
       "      <td>32</td>\n",
       "      <td>1E-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.489663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  adam_epsilon batch_size learning_rate num_epochs validation loss\n",
       "0        1E-08         32         1E-05          5        0.489663"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperdrive_run.wait_for_completion(show_output = False)\n",
    "\n",
    "children = list(hyperdrive_run.get_children())\n",
    "metricslist = {}\n",
    "i = 0\n",
    "\n",
    "for single_run in children:\n",
    "    results = {k: v for k, v in single_run.get_metrics().items() if isinstance(v, float)}\n",
    "    parameters = single_run.get_details()['runDefinition']['arguments']\n",
    "    try:\n",
    "        results['batch_size'] = parameters[3]\n",
    "        results['learning_rate'] = parameters[5]\n",
    "        results['adam_epsilon'] = parameters[7]\n",
    "        results['num_epochs'] = parameters[9]\n",
    "        metricslist[i] = results\n",
    "        i += 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "rundata = pd.DataFrame(metricslist).sort_index(1).T.sort_values(by = ['validation loss'], ascending = True)\n",
    "rundata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access directly the best run from our hyperdrive execution and then have access to the generated log files and the outputs we create explicitly.\n",
    "\n",
    "We can also save this reference number, and use it later to retrieve the bets run and associated artifacts saves during its execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert_text_classification_distributed_1580183281896998_0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All files that we write to the special \"outputs\" folder are made available for each hyperdrive run. Here we list those generated by the best run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azureml-logs/55_azureml-execution-tvmps_40be941cd6e7fdbb4a4c29f7d88615d0234114e775eac1b9759e345478708556_d.txt',\n",
       " 'azureml-logs/55_azureml-execution-tvmps_6ac160721fbb4a462c53968dfe47dc899a2747e4f07ee85869d6942530b2d55c_d.txt',\n",
       " 'azureml-logs/55_azureml-execution-tvmps_c4aa518317696ff9d5fcc5b1903280575b50c5bd08c89d02701ae6c40888ca78_d.txt',\n",
       " 'azureml-logs/55_azureml-execution-tvmps_c696483192492da13bd69d5e0fc181d5b1850480a5e33e52e16f4cf8b65c87a3_d.txt',\n",
       " 'azureml-logs/55_azureml-execution-tvmps_ce123e5e7010f950bfba0584d0f6585a5dfee40a3ffeb359f3692e49628260af_d.txt',\n",
       " 'azureml-logs/55_azureml-execution-tvmps_d641a9cc30742828d4156e8cc219c536752fc449b75da6e5131d604a8381ec31_d.txt',\n",
       " 'azureml-logs/55_azureml-execution-tvmps_f29b0667db008a7626bd458db1f1ed62a414471b40aa64cbdb5fcf2220384a21_d.txt',\n",
       " 'azureml-logs/55_azureml-execution-tvmps_f64683dc0d6661da73ef63e9bd5144d6a5689db1de46424730bd71aa5bb0bc10_d.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_40be941cd6e7fdbb4a4c29f7d88615d0234114e775eac1b9759e345478708556_d.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_6ac160721fbb4a462c53968dfe47dc899a2747e4f07ee85869d6942530b2d55c_d.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_c4aa518317696ff9d5fcc5b1903280575b50c5bd08c89d02701ae6c40888ca78_d.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_c696483192492da13bd69d5e0fc181d5b1850480a5e33e52e16f4cf8b65c87a3_d.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_ce123e5e7010f950bfba0584d0f6585a5dfee40a3ffeb359f3692e49628260af_d.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_d641a9cc30742828d4156e8cc219c536752fc449b75da6e5131d604a8381ec31_d.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_f29b0667db008a7626bd458db1f1ed62a414471b40aa64cbdb5fcf2220384a21_d.txt',\n",
       " 'azureml-logs/65_job_prep-tvmps_f64683dc0d6661da73ef63e9bd5144d6a5689db1de46424730bd71aa5bb0bc10_d.txt',\n",
       " 'azureml-logs/70_driver_log_0.txt',\n",
       " 'azureml-logs/70_driver_log_1.txt',\n",
       " 'azureml-logs/70_driver_log_2.txt',\n",
       " 'azureml-logs/70_driver_log_3.txt',\n",
       " 'azureml-logs/70_driver_log_4.txt',\n",
       " 'azureml-logs/70_driver_log_5.txt',\n",
       " 'azureml-logs/70_driver_log_6.txt',\n",
       " 'azureml-logs/70_driver_log_7.txt',\n",
       " 'azureml-logs/70_mpi_log.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_40be941cd6e7fdbb4a4c29f7d88615d0234114e775eac1b9759e345478708556_d.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_6ac160721fbb4a462c53968dfe47dc899a2747e4f07ee85869d6942530b2d55c_d.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_c4aa518317696ff9d5fcc5b1903280575b50c5bd08c89d02701ae6c40888ca78_d.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_c696483192492da13bd69d5e0fc181d5b1850480a5e33e52e16f4cf8b65c87a3_d.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_ce123e5e7010f950bfba0584d0f6585a5dfee40a3ffeb359f3692e49628260af_d.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_d641a9cc30742828d4156e8cc219c536752fc449b75da6e5131d604a8381ec31_d.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_f29b0667db008a7626bd458db1f1ed62a414471b40aa64cbdb5fcf2220384a21_d.txt',\n",
       " 'azureml-logs/75_job_post-tvmps_f64683dc0d6661da73ef63e9bd5144d6a5689db1de46424730bd71aa5bb0bc10_d.txt',\n",
       " 'azureml-logs/process_info.json',\n",
       " 'azureml-logs/process_status.json',\n",
       " 'logs/azureml/0_143_azureml.log',\n",
       " 'logs/azureml/1_118_azureml.log',\n",
       " 'logs/azureml/2_117_azureml.log',\n",
       " 'logs/azureml/3_117_azureml.log',\n",
       " 'logs/azureml/4_118_azureml.log',\n",
       " 'logs/azureml/5_116_azureml.log',\n",
       " 'logs/azureml/6_116_azureml.log',\n",
       " 'logs/azureml/7_118_azureml.log',\n",
       " 'logs/azureml/job_prep_azureml.log',\n",
       " 'logs/azureml/job_release_azureml.log',\n",
       " 'outputs/added_tokens.json',\n",
       " 'outputs/config.json',\n",
       " 'outputs/pytorch_model.bin',\n",
       " 'outputs/special_tokens_map.json',\n",
       " 'outputs/tokenizer_config.json',\n",
       " 'outputs/train_losses.pkl',\n",
       " 'outputs/val_losses.pkl',\n",
       " 'outputs/vocab.txt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = Run(Experiment(workspace = workspace, name = 'bert_text_classification_distributed'), 'bert_text_classification_distributed_1580183281896998_0')\n",
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we didn’t specify the compute target to scale down automatically, we can explicitly delete it. This will stop and delete all associated compute resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then retrieve the saved model, corresponding configurations, and logged metrics that we explicitly saved in the run script and use them to recreate the model and evaluate it on the test data, as we did in the previous notebook when showing the fine-tuning process step-by-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = './model_aml'\n",
    "os.makedirs(model_folder, exist_ok = True)\n",
    "\n",
    "for f in run.get_file_names()[-8:]:\n",
    "    run.download_file(f, model_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
